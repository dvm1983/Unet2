{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "from lib import *\n",
    "\n",
    "import albumentations as albu\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "from utils.trainer import Trainer\n",
    "from utils.data.datasets import CustomDataset\n",
    "from utils.data.datasets import get_preprocessing\n",
    "from utils.scorer import DiceLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentations = [albu.HorizontalFlip(),\n",
    "                 albu.OneOf([albu.IAAAdditiveGaussianNoise(), \n",
    "                             albu.GaussNoise()], p=0.2),\n",
    "                 albu.OneOf([albu.MotionBlur(p=0.2), \n",
    "                             albu.MedianBlur(blur_limit=3, p=0.1), \n",
    "                             albu.Blur(blur_limit=3, p=0.1)], p=0.2),\n",
    "                 albu.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.2, rotate_limit=30, p=0.15),\n",
    "                 albu.ToGray(p=0.1)]\n",
    "transforms = albu.Compose(augmentations, p=0.5)\n",
    "\n",
    "transforms = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"./data/train\"\n",
    "val_path = \"./data/valid\"\n",
    "test_path = \"./data/test\"\n",
    "style_transfer_path = None #val_path\n",
    "\n",
    "encoder = 'resnet152'\n",
    "encoder_weights = 'imagenet'\n",
    "device = 'cuda'\n",
    "lr = 1e-4\n",
    "mixup_proba = None #0.1\n",
    "batch_size = 16\n",
    "n_epoch = 15\n",
    "num_workers = 0\n",
    "model_name = f'unet_{encoder}_trnsfrm={int(transforms is not None)}_mxp={int(mixup_proba is not None)}_stl={int(style_transfer_path is not None)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp.Unet(encoder_name=encoder, encoder_weights=encoder_weights)\n",
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(encoder, encoder_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(data_path=train_path, transforms=transforms,\\\n",
    "                              preprocessing=get_preprocessing(preprocessing_fn), mixup_proba=mixup_proba,\n",
    "                              style_transfer_path=style_transfer_path)\n",
    "val_dataset = CustomDataset(data_path=val_path, transforms=transforms,\\\n",
    "                            preprocessing=get_preprocessing(preprocessing_fn), style_transfer_path=None)\n",
    "    \n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, device=device, model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = trainer.train(train_dataloader=train_loader, val_dataloader=val_loader , n_epoch=n_epoch,\\\n",
    "              optim=torch.optim.Adam, weight_decay=0.0,\\\n",
    "              schedul=None, loss=DiceLoss(), lr=lr, show_results=True,\\\n",
    "              saved_models_dir=None, verbose=True, early_stopping=True, max_gap=2, gamma=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.pop('loss_train')\n",
    "history.pop('loss_val')\n",
    "pd.DataFrame.from_dict(history, orient='index', columns=[model_name]).to_excel(f'./results/{model_name}.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(data_path=test_path, masks=False, transforms=None, preprocessing=get_preprocessing(preprocessing_fn))\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "th = 0.6\n",
    "model.eval()\n",
    "files = os.listdir(test_path)\n",
    "pred_masks = []\n",
    "pred_masks_rle = []\n",
    "paths_to_imgs = []\n",
    "for img_id, src in enumerate(test_loader):\n",
    "    mask = model(src.to(device))\n",
    "    mask = mask.detach().cpu().numpy().reshape(320, 320)\n",
    "    mask = (mask >= th).astype('uint8')\n",
    "    mask = mask*255\n",
    "    \n",
    "    pred_masks.append(mask)\n",
    "    pred_masks_rle.append(encode_rle(mask))\n",
    "    paths_to_imgs.append(f\"{test_path}/{files[img_id]}\")\n",
    "    \n",
    "    img = np.array(Image.open(f\"{test_path}/{files[img_id]}\"))\n",
    "    mask = cv2.resize(mask, (img.shape[1], img.shape[0]))\n",
    "    show_img_with_mask(img, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset = CustomDataset(data_path=val_path, masks=False, transforms=None, preprocessing=get_preprocessing(preprocessing_fn))\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th = 0.6\n",
    "model.eval()\n",
    "files = os.listdir(val_path)\n",
    "pred_masks = []\n",
    "pred_masks_rle = []\n",
    "paths_to_imgs = []\n",
    "for img_id, src in enumerate(valid_loader):\n",
    "    img = np.array(Image.open(f\"{val_path}/{files[img_id]}\"))\n",
    "    mask = model(src.to(device))\n",
    "    mask = mask.detach().cpu().numpy().reshape(320, 320)\n",
    "    mask = (mask >= th).astype('uint8')\n",
    "    mask = mask*255\n",
    "    mask = cv2.resize(mask, (img.shape[1], img.shape[0]))\n",
    "    mask[mask > 0] = 255\n",
    "    pred_masks.append(mask.astype('uint8'))\n",
    "    pred_masks_rle.append(encode_rle(mask))\n",
    "    paths_to_imgs.append(f\"{val_path}/{files[img_id]}\")\n",
    "\n",
    "    show_img_with_mask(img, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [int(x.split('.')[0]) for x in files]\n",
    "df = pd.DataFrame(ids, columns=['id'])\n",
    "df['rle_mask'] = pred_masks_rle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('pred_valid.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = get_html(paths_to_imgs, pred_masks, path_to_save=\"./results/example\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
